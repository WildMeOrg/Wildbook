

#### IBEIS IA settings
#IBEISIARestUrlAddImages = http://localhost:5000/api/image/json/
#IBEISIARestUrlAddAnnotations = http://localhost:5000/api/annot/json/
#IBEISIARestUrlStartIdentifyAnnotations = http://localhost:5000/api/engine/query/graph/
#IBEISIARestUrlIdentifyReview = http://localhost:5000/api/review/query/graph/
#IBEISIARestUrlStartDetectImages = http://localhost:5000/api/engine/detect/cnn/yolo/
####IBEISIARestUrlStartDetectImages = http://localhost:5000/api/detect/cnn/yolo/json/
#IBEISIARestUrlDetectReview = http://localhost:5000/api/review/detect/cnn/yolo/
#IBEISIARestUrlGetJobStatus = http://localhost:5000/api/engine/job/status/
#IBEISIARestUrlGetJobResult = http://localhost:5000/api/engine/job/result/

#### enable this to *only* do detection (wont continue to identification)
IBEISIADisableIdentification = true

#unless set true, ID needs taxonomy (not just for menu) - default is FALSE
#   when no taxonomy, ID will match against *all* possible annots, regardless of species
#allowIdentificationWithoutTaxonomy = false

#### If true requires species to be set for hamburger menu ID options.
#requireSpeciesForId = false

#unless set true, ID needs taxonomy (not just for menu) - default is FALSE
#   when no taxonomy, ID will match against *all* possible annots, regardless of species
#   TODO should this be combined with above?
#allowIdentificationWithoutTaxonomy = false

### these are to create more than one start option.  if none provided, default (empty hash "{}") will be used
###    *must* be valid json object
#IBEISIdentOpt0={}
### this example enables identify by edge detection
#IBEISIdentOpt1={"queryConfigDict": {"pipeline_root": "OC_WDTW"} }
### this example is CurvRank
#IBEISIdentOpt2={"queryConfigDict": {"pipeline_root": "CurvRankFluke"} }


#you can also do one or more identOpts based on scientific name (note trailing integer that is required!) :
#IBEISIdentOpt_Scientific_name_here0={"foobar": true}


##### these are how we map IA classifier "species" to WB internal taxonomy... put as many as we need (increment digit at end)
#####  classes returned via ia for detection which *are not* in this list will CAUSE RESULTS TO BE IGNORED ("invalid species")
#####  so it is worth noting that leaving this empty effectively gets you no detection!!
#detectionClass0 = ia_class_fubar
#taxonomyScientificName0 = Fuus barrus

#####  this is optional -- if not included, default model is used
#modelTag = some_special_model
#modelTag_Scientific_name = another_model_based_on_taxonomy

#####  also optional -- if IA is configured with a viewpoint-labeler this identifies the model used
#viewpointModelTag_Scientific_name = yet_another_model_based_on_taxonomy
### a little clunky, but the following tags map (both ways!) a WB keyword name to an IA viewpoint value
### iaviewpointtag must be verbatim the value returned by IA, which will be mapped to the appropriate WB keyword
#viewpointModelTag_Scientific_name_iaviewpointtag = WB Verbatim Keyword Name
#viewpointModelTag_Scientific_name_anotheriaviewpointtag = WB Verbatim Keyword Name 2
#viewpointModelTag_WB_Verbatim_Keyword_Name = iaviewpointtag
#viewpointModelTag_WB_Verbatim_Keyword_Name_2 = anotheriaviewpointtag

#### likewise optional; used for viewpoint labeling
#labelerAlgo=densenet
#labelerModelTag=giraffe_v1

#sensitivity = 0.7
#nms_thresh = 0.40

#note: you can do a specific detection url for a specific model by using:
#IBEISIARestUrlStartDetectImages.modelTag_goes_here = http://localhost:5000/api/engine/detect/cnn/lightnet/


#### likewise optional; used for viewpoint labeling
#labelerAlgo=densenet
#labelerModelTag=giraffe_v1


#####  also optional -- if IA is configured with a viewpoint-labeler this identifies the model used
#viewpointModelTag_Scientific_name = yet_another_model_based_on_taxonomy
### a little clunky, but the following tags map (both ways!) a WB keyword name to an IA viewpoint value
### iaviewpointtag must be verbatim the value returned by IA, which will be mapped to the appropriate WB keyword
#viewpointModelTag_Scientific_name_iaviewpointtag = WB Verbatim Keyword Name
#viewpointModelTag_Scientific_name_anotheriaviewpointtag = WB Verbatim Keyword Name 2
#viewpointModelTag_WB_Verbatim_Keyword_Name = iaviewpointtag
#viewpointModelTag_WB_Verbatim_Keyword_Name_2 = anotheriaviewpointtag


#note: you can do a specific detection url for a specific model by using:
#IBEISIARestUrlStartDetectImages.modelTag_goes_here = http://localhost:5000/api/engine/detect/cnn/lightnet/
#sensitivity = 0.7
#nms_thresh = 0.40

########## YouTube Bot
#Max frames between animal presence in video before creating another encounter. Whaleshark = 4
newEnounterFrameGap=20

#### probably only want this in spot-based matching (e.g. whaleshark, etc)
####  DEPRECATED!!!   going to decide this based on 'useSpotPatternRecognition' in commonConfiguration
#####sharkGrid.startMatchGraph = true



########################## Extracted Class Keywords
## Since coloration (wild dogs) is appended to the species portion of the class for body
## and to the part portion of the class for parts detection, there is no clear way to extract them. 
## This is especially true since some species models will have them and others will not. 
## To squeeze around this, here are EXTRACTED KEYWORDS. Look for these words, across class strings,
## and set them as an keyword. This isn't awesome AT ALL, lets come up with a better way. 
## It's going to be tragically flawed until we have ANNOTATION LEVEL KEYWORDS/LABELS. --colin

iaExtractedKeyword0=standard #substring of the returned iaClass
iaExtractedKeywordValue=Standard Coloration #the keyword you want set on the asset 